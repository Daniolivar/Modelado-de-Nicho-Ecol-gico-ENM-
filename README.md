# Modelado de Nicho Ecologico ENM
Modelado de Nicho Ecol√≥gico (ENM) del fitopat√≥geno Colletotrichum gloeosporioides en las Am√©ricas usando R y ENMeval. Implementaci√≥n de un enfoque de fondo restringido por hospederos (Aguacate, Mango, Papaya, Fresa) para evitar sesgos geogr√°ficos y mejorar la precisi√≥n biol√≥gica.

üéØ Objetivo
Identificar zonas de alto riesgo clim√°tico para la antracnosis en las Am√©ricas, restringiendo el an√°lisis a las √°reas agr√≠colas donde sus hospederos principales est√°n presentes, para evitar sesgos ecol√≥gicos triviales.

üõ†Ô∏è Metodolog√≠a 
Datos de Presencia: Descarga y limpieza de registros de GBIF para C. gloeosporioides (n = 1,404). Se implement√≥ una limpieza de coordenadas personalizada para evitar conflictos de paquetes.

Definici√≥n del √Årea M (Fondo):

Se descart√≥ el uso de un fondo global o continental.

Se construy√≥ una m√°scara de "Hospederos Disponibles" basada en la distribuci√≥n de Aguacate (Persea americana), Mango (Mangifera indica), Fresa (Fragaria) y Papaya (Carica papaya).

Variables Clim√°ticas: Selecci√≥n basada en biolog√≠a y baja colinealidad:

bio10: Temperatura media del trimestre m√°s c√°lido.

bio12: Precipitaci√≥n anual.

bio15: Estacionalidad de la precipitaci√≥n.

Modelado: Se utiliz√≥ el paquete ENMeval 2.0 con el algoritmo maxnet (Maxent sin Java). Se evaluaron 15 configuraciones de modelo (feature classes L, Q, H, LQ, LQH y regularizaci√≥n 1-3).

üìä Resultados Principales
Mejor Modelo: Configuraci√≥n LQH con rm = 1.

Desempe√±o: AUC de Validaci√≥n = 0.827. La diferencia entre AUC de entrenamiento y validaci√≥n fue m√≠nima (0.006), indicando ausencia de sobreajuste.

Test de Nulidad: El modelo es significativamente mejor que el azar (p < 0.01).





## üì¶ 1. Configuraci√≥n del Entorno

Para garantizar la reproducibilidad del an√°lisis, este flujo de trabajo utiliza un conjunto espec√≠fico de librer√≠as de R para la descarga de datos, el manejo espacial y el modelado ecol√≥gico.

Se utilizan paquetes como `maxnet` para evitar dependencias externas complejas (como Java) y `CoordinateCleaner` para asegurar la calidad de los datos biol√≥gicos.

```r
install.packages(c(
  "rgbif",              # Descarga de ocurrencias de GBIF
  "CoordinateCleaner",  # Limpieza automatizada de coordenadas
  "geodata",            # Descarga de clima (WorldClim)
  "terra",              # Manejo de datos raster y vectoriales
  "sf",                 # Operaciones espaciales simples
  "dplyr",              # Manipulaci√≥n de datos
  "stringr",            # Manejo de cadenas de texto
  "ENMeval",            # Calibraci√≥n y evaluaci√≥n de modelos
  "maxnet"              # Algoritmo Maxent (versi√≥n R pura)
))



# --- 1. CARGAR LIBRER√çAS ----
library(rgbif)
library(CoordinateCleaner) # ¬°Clave para la limpieza!
library(geodata)
library(terra)
library(sf)
library(dplyr)
library(stringr) #
```

1.1 Definici√≥n de Funci√≥n de Descarga Robusta
Para asegurar la reproducibilidad y evitar errores comunes en la descarga de datos (como desconexiones o inconsistencias en las columnas entre continentes), definimos la funci√≥n personalizada get_occurrences_america_V7.

Esta funci√≥n implementa:

Descarga segura por continente (Norte y Sur Am√©rica).

Manejo de errores (evita fallos si GBIF retorna NULL).

Uni√≥n inteligente de datos usando bind_rows.

Limpieza automatizada con CoordinateCleaner.

Conversi√≥n forzada a data.frame base para evitar conflictos con terra::extract en pasos posteriores.

Fragmento de c√≥digo

# 2. Definir Funci√≥n de Descarga Robusta (V7.0)
get_occurrences_america_V7 <- function(species_name, limit = 10000, clean_data = TRUE) {
  
  print(paste("Descargando:", species_name, "(Norteam√©rica)..."))
  data_na <- occ_search(
    scientificName = species_name,
    continent = "north_america",
    hasCoordinate = TRUE,
    limit = limit
  )$data
  
  print(paste("Descargando:", species_name, "(Sudam√©rica)..."))
  data_sa <- occ_search(
    scientificName = species_name,
    continent = "south_america",
    hasCoordinate = TRUE,
    limit = limit
  )$data
  
  if (is.null(data_na)) data_na <- data.frame()
  if (is.null(data_sa)) data_sa <- data.frame()

  print("Combinando datos...")
  df <- dplyr::bind_rows(data_na, data_sa)
  
  if (nrow(df) == 0) {
    print("No se encontraron registros.")
    return(data.frame(decimalLongitude=numeric(), decimalLatitude=numeric()))
  }

  target_cols <- c("decimalLongitude", "decimalLatitude", "species")
  available_cols <- intersect(target_cols, names(df))
  
  df <- df %>%
    # ¬°AQU√ç EST√Å LA PRIMERA CORRECCI√ìN!
    dplyr::select(all_of(available_cols)) %>%
    dplyr::filter(!is.na(decimalLongitude), !is.na(decimalLatitude))

  if (nrow(df) == 0) {
    print("No se encontraron registros tras el filtro inicial.")
    return(data.frame(decimalLongitude=numeric(), decimalLatitude=numeric()))
  }
  
  print(paste("Total de registros brutos:", nrow(df)))
  
  if (clean_data) {
    print("Limpiando coordenadas...")
    if (!"species" %in% names(df)) {
      df$species <- species_name
    }
    df_clean <- clean_coordinates(
      x = df,
      lon = "decimalLongitude",
      lat = "decimalLatitude",
      species = "species",
      tests = c("centroids", "equal", "gbif", "institutions", "zeros")
    ) %>% filter(.summary == TRUE)
    
    print(paste("Total de registros limpios:", nrow(df_clean)))
    
    # --- ¬°LA CORRECCI√ìN CLAVE QUE ARREGLA TODO! ---
    # Forzamos la conversi√≥n a data.frame y usamos dplyr::select
    df_final <- as.data.frame(df_clean) %>%
      dplyr::select(decimalLongitude, decimalLatitude)
    # ---------------------------------------------
      
  } else {
    print("Omitiendo CoordinateCleaner.")
    df_final <- df %>%
      dplyr::select(decimalLongitude, decimalLatitude)
  }
  return(df_final)
}
1.2 Adquisici√≥n de Datos del Pat√≥geno


